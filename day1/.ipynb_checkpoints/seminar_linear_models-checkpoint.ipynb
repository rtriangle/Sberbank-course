{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUWCAY5opP87"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wj5MrpmRpP89"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b> Градиентный спуск. Линейные модели.</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTi8pD-2LM3r"
   },
   "source": [
    "В этом ноутбуке мы попробуем реализовать свой градиентный спуск на основе модели линейной регрессии и сравним свою реализацию с sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0Fu3DXZ01RLE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "import scipy.linalg as sla\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4pKjcf4SQEF"
   },
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ao0ab4nESQEH"
   },
   "source": [
    "Модель нашей линейной решрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "APZu5Ra7xn6s"
   },
   "outputs": [],
   "source": [
    "# в этих переменных будут лежать веса, которые мы оценим\n",
    "# W - веса модели, на которые умножаются признаки\n",
    "W = None\n",
    "# b - bias, который добавляется к итоговому результату\n",
    "b = None\n",
    "\n",
    "def mse(preds, y):\n",
    "    \"\"\"\n",
    "    Возвращает среднеквадратичную ошибку между preds и y.\n",
    "    \"\"\"\n",
    "    return ((preds - y)**2).mean()\n",
    "\n",
    "def solve_weights(X, y):\n",
    "    \"\"\"\n",
    "    Находит параметры W, b по методу наименьших квадратов для X и y.\n",
    "    Решает систему линейных уравнений, к которым приводит метод наименьших \n",
    "    квадратов, для признаков X и значений y.\n",
    "    \"\"\"\n",
    "    # ключевое слово global позволяет нам использовать глобальные переменные,\n",
    "    # определенные в начале ячейки\n",
    "    global W, b\n",
    "    \n",
    "    \n",
    "    N = X.shape[0]\n",
    "    # добавляем к признакам фиктивную размерность, чтобы было удобнее находить bias\n",
    "    bias = np.ones((N, 1))\n",
    "    X_b = np.append(bias, X, axis=1)\n",
    "    \n",
    "    # используем формулу из метода наименьших квадратов\n",
    "    # W_full сожержит коэффициенты W и b, так как мы добавили фиктивную размерность к признакам\n",
    "    W_full = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "    \n",
    "    # мы разделяем bias, который лежал в начале вектора W_full, и веса модели W\n",
    "    W = W_full[1:]\n",
    "    b = np.array([W_full[0]])\n",
    "    # нам не нужно возвращать W и b, так как они уже лежат в глобальных переменных\n",
    "    \n",
    "def grad_descent(X, y, lr, num_iter=100):\n",
    "    \"\"\"\n",
    "    Находит приближенные значения параметров модели, используя градиентный спуск.\n",
    "    Функции потерь (ошибки) для данной реализации спуска - сумма квадратов ошибки.\n",
    "    Возвращаемое значение - список значений ффункции потерь на каждом шаге.\n",
    "    \"\"\"\n",
    "    # ключевое слово global позволяет нам использовать глобальные переменные,\n",
    "    # определенные в начале ячейки\n",
    "    global W, b\n",
    "    W = np.random.rand(X.shape[1])\n",
    "    b = np.array(np.random.rand(1))\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    for iter_num in range(num_iter):\n",
    "        preds = predict(X)\n",
    "        losses.append(mse(preds, y))\n",
    "        \n",
    "        w_grad = np.zeros_like(W)\n",
    "        b_grad = 0\n",
    "        for sample, prediction, label in zip(X, preds, y):\n",
    "            w_grad += 2 * (prediction - label) * sample\n",
    "            b_grad += 2 * (prediction - label)\n",
    "            \n",
    "        W -= lr * w_grad\n",
    "        b -= lr * b_grad\n",
    "    return losses\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\"\n",
    "    Предсказывает значения y, используя текущие параметры модели W и b\n",
    "    \"\"\"\n",
    "    global W, b\n",
    "    return np.squeeze(X@W + b.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWtYzIacBLwi"
   },
   "source": [
    "Подробнее рассмотрим формулы, которые используются в градиентном спуске.\n",
    "Наша функция потерь \n",
    "$$L(\\hat{y}) = \\sum_{i = 1}^{N}( \\hat{y}_{i} - y_{i} )^{2}$$\n",
    "Найдем производную:\n",
    "$$\\frac{dL(\\hat{y})}{d\\hat{y}} = \\sum_{i = 1}^{N}2(\\hat{y}_{i} - y_{i} )$$\n",
    "Где $\\hat{y}$ это вектор предсказаний, а $y$ - вектор значений. Если у нас есть только два признака, то по определению нашей модели:\n",
    "$$\\hat{y}_{i} = W_1 * x_{i1} + W_2 * x_{i2} + b$$\n",
    "\n",
    "Подставим в формулу для функции потерь и возьмём производную:\n",
    "$$\\frac{\\partial L(\\hat{y})}{ \\partial W_1} = \\sum_{i = 1}^{N} \\frac{\\partial (( \\hat{y}_{i} - y_{i} )^{2})}{\\partial \\hat{y_i}} \\times \\frac{\\partial \\hat{y_i}}{\\partial W_1}  =  \n",
    "\\sum_{i = 1}^{N} 2 (\\hat{y_i} - y) \\times x_{i1} $$\n",
    "\n",
    "\n",
    "В формуле есть суммирование по всем строчкам $X$ ($x_i$ это $i$-ая строчка X, в которой хранятся признаки для $i$-го наблюдения), в коде ему соответствует внешний цикл, итерирующийся по всем наблюдениям. Внутренний цикл нужен для получения производных по всем весам $W_i$, которых в общем случае может быть произвольное количество.\n",
    "\n",
    "\n",
    "В итоге выполнения кода \n",
    "$$w\\_grad = (\\frac{\\partial L(\\hat{y})}{\\partial W_1} , \\frac{\\partial L(\\hat{y})}{\\partial W_2}, \\frac{\\partial L(\\hat{y})}{\\partial W_3} ,...) = \\nabla L$$ \n",
    "\n",
    "Для обновления весов мы вычитаем градиент, передвигаясь в направлении скорейшего убывания функции.\n",
    "$$W = W - lr \\cdot \\nabla L$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxys5OMESQEN"
   },
   "source": [
    "### Получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GvGNqv-QhFCq"
   },
   "outputs": [],
   "source": [
    "def generate_data(range_, a, b, std, num_points=100):\n",
    "    \"\"\"Генерирует данные в заданном промежутке, которые подчиняются зависимости y = a*x + b + е,\n",
    "    где е - нормально распределено со стандартным отклонением std и нулевым средним.\"\"\"\n",
    "    X_train = np.random.random(num_points) * (range_[1] - range_[0]) + range_[0]\n",
    "    y_train = a * X_train + b + np.random.normal(0, std, size=X_train.shape)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1539364049842,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "kfjNWvxPSQEO",
    "outputId": "180869e0-ae28-40c8-858e-f766937e6efe"
   },
   "outputs": [],
   "source": [
    "# Зададим параметры для искусственных данных\n",
    "real_a = 0.34\n",
    "real_b = 13.7\n",
    "real_std = 7\n",
    "\n",
    "# Генерируем данные для промежутка от 0 до 150 с параметрами, которые мы задали выше\n",
    "X_train, y_train = generate_data([0, 150], real_a, real_b, real_std)\n",
    "\n",
    "# просто выведем табличку с данными\n",
    "pd.DataFrame({'X': X_train, 'Y': y_train}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2125,
     "status": "ok",
     "timestamp": 1539364052157,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "uyjHOvSuSQEY",
    "outputId": "ad787647-3b81-43ff-f03d-fa500dbdbeaa"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, c='black')\n",
    "plt.plot(X_train, 0.34*X_train+13.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSsVqF20SQEj"
   },
   "source": [
    "### Решение с помощью линейной алгебры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rqMulvKhSQEk"
   },
   "outputs": [],
   "source": [
    "# Используем функцию, написанную выше, чтобы найти W и b, с помощтю метода наименьших квадратов\n",
    "solve_weights(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1539364054213,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "JnVSSMNGSQEo",
    "outputId": "7154fc6c-b5d9-4b7a-ca67-266191ed87c0"
   },
   "outputs": [],
   "source": [
    "# Полученные веса лежат в глобальных переменных, выведем их\n",
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBwYctcZhFDR"
   },
   "source": [
    "Полученные веса очень похожи на те, которые мы задавали при генерации данных. Значит модель получилась хорошей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1539364055884,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "T8pcThvvSQEt",
    "outputId": "f57c4745-f6d0-4090-8171-dc92cc274609"
   },
   "outputs": [],
   "source": [
    "# Выведем данные, истинную зависимость и полученную нами с помощью метода наименьших квадратов\n",
    "plt.scatter(X_train, y_train, c='r')\n",
    "plt.plot(X_train, 0.34*X_train+13.7)\n",
    "plt.plot(X_train, np.squeeze(X_train.reshape(-1, 1) @ W + b.reshape(-1, 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MTk_FR2SQEy"
   },
   "source": [
    "### Решение с помощью градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m850g9haSQE1"
   },
   "outputs": [],
   "source": [
    "# Найдем параметры с помощью градиентного спуска\n",
    "# чтобы проследить за обучением, мы записываем значение функции ошибки на каждом шаге и после выводим\n",
    "losses = grad_descent(X_train.reshape(-1, 1), y_train, 1e-9, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1539364064208,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "25dgBfNuSQE9",
    "outputId": "b729d5fc-9ef5-4c15-a4d4-41d8ab12faba"
   },
   "outputs": [],
   "source": [
    "# Полученные веса лежат в глобальных переменных, выведем их\n",
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-3mvFTRhFEV"
   },
   "source": [
    "Веса модели получились не похожи, на то, что мы задавали при генерации данных. Модель намного хуже.\n",
    "\n",
    "Стоит отметить, что хуже всего был подобран свободный член b, это связано с тем, что данные не нормализованы и параметры a и b имеют очень разные модули, а шаги, которые делает градиентный спуск для обоих параметров одного порядка. Это приводит к тому, что меньший по модулю параметр a быстро подбирается, а параметр почти b перестает изменяться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1539364066361,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "Hhop71KlSQFB",
    "outputId": "c7c1d664-6ca2-4f6a-a129-e37dc6666268"
   },
   "outputs": [],
   "source": [
    "# Выведем график функции потерь \n",
    "plt.plot(losses), losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1539364068547,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "ItCyBwfwSQFH",
    "outputId": "58795acc-67a4-4d7e-b0bf-3f3bc5b29fc0"
   },
   "outputs": [],
   "source": [
    "# Выведем данные, истинную зависимость и полученную нами\n",
    "plt.scatter(X_train, y_train, c='r')\n",
    "plt.plot(X_train, real_a * X_train + real_b)\n",
    "plt.plot(X_train, np.squeeze(X_train.reshape(-1, 1) @ W + b.reshape(-1, 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edEx8RuJhFEw"
   },
   "source": [
    "Градиентный спуск восстановил зависимость хуже, чем метод наименьших квадратов, это вызвано тем, что \n",
    "* данные не **нормализованы** (подробнее о нормализации в домашнем ноутбуке).\n",
    "* в **методе наименьших квадратов** мы получали решение **аналитически**, поэтому оно гарантировано является наилучшим, в то время как градиентный спуск находит решение лишь приближенно. \n",
    "\n",
    "Возникает вопрос, зачем использовать **градиентный спуск**, если он хуже **аналитических** мтеодов? Дело в том, что оптимизация большого количества весов в **нейронных сетях** сликшом сложная задача, которая не может быть решена **аналитически**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6VOEaY2SQFO"
   },
   "source": [
    "### Данные посложнее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rNOb6iuJLB-"
   },
   "source": [
    "Загрузим с помощью **pandas** реальные данные и попробуем найти параметры зависимости с помощью метода наименьших квадратов и градиентного спуска, как и в предыдущем примере (так как наш код универсален, нам просто нужно просто вызвать те же функции)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cG4n12xvSQFP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uGCTic-qSQFV",
    "outputId": "32fd5980-fdf6-4bb6-f676-bc35d5c0af2d"
   },
   "outputs": [],
   "source": [
    "# так как данные многомерные, мы не можем построить график, как в предыдущем примере, \n",
    "# чтобы увидеть зависимость глазами. Поэтому мы просто выведем первые строки таблицы.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2VdsqMNFSQFb"
   },
   "outputs": [],
   "source": [
    "# разделим данные на признаки и значения\n",
    "data, label = np.array(df)[:, 1:5], np.array(df)[:, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knOBphGnSQFi"
   },
   "source": [
    "### Решение с помощью линейной алгебры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eV3TJ92fSQFj"
   },
   "outputs": [],
   "source": [
    "# Используем функцию, написанную выше, чтобы найти W и b, с помощтю метода наименьших квадратов\n",
    "solve_weights(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0Yfhm4fISQFm",
    "outputId": "9e9e5af2-7eba-46c4-8959-dd2fef9adae5"
   },
   "outputs": [],
   "source": [
    "# Полученные веса лежат в глобальных переменных, выведем их\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KVag7u66SQFq",
    "outputId": "2a6398d5-ad59-423d-8428-6123aeeb202f"
   },
   "outputs": [],
   "source": [
    "# Выведем значение функции ошибки, чтобы позже сравнить с результатом градиентного спуска\n",
    "mse(predict(data), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJqoPz4RSQFt"
   },
   "source": [
    "### Решение с помощью градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cFXllJyQSQFv"
   },
   "outputs": [],
   "source": [
    "# Найдем параметры с помощью градиентного спуска\n",
    "# чтобы проследить за обучением, мы записываем значение функции ошибки на каждом шаге и после выводим\n",
    "losses = grad_descent(data, label, 1e-9, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "27q36bXrSQF1",
    "outputId": "f8351eeb-6bb4-44ad-89ed-776d2f2586f4"
   },
   "outputs": [],
   "source": [
    "# Полученные веса лежат в глобальных переменных, выведем их\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0MzZJdjQSQF5",
    "outputId": "b1f5031c-c346-4788-c155-eeeacb21cc82"
   },
   "outputs": [],
   "source": [
    "# Выведем график функции потерь \n",
    "plt.plot(losses), losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GqmUW4-lLPq_",
    "outputId": "3c28cdb2-84f1-4ef7-a8a8-49868c0a31ac"
   },
   "outputs": [],
   "source": [
    "# Выведем значение функции ошибки\n",
    "mse(predict(data), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws5k-CQChFFi"
   },
   "source": [
    "Как мы видим, **градиентный спуск** опять нашел значительно более плохое решение. Если нормализовать данные, то **градиентный спуск** будет сходиться лучше и разница будет не такой заметной. \n",
    "\n",
    "В домашнем задании вы научитесь нормализовывать данные. После этого вы можете вернуться в этот ноутбук и запустить градиентный спуск, предварительно использовав нормализацию."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar]linear_models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
